{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc883d8-2d79-4be3-aeb6-3117637f88b2",
   "metadata": {},
   "source": [
    "# Chapter 7: Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba74c08f-1b10-4e29-91ea-ea9ab1726e03",
   "metadata": {},
   "source": [
    "## Building a Review-Based QA System\n",
    "\n",
    "### The Dataset\n",
    "\n",
    "> SubjQA is a question answering dataset that focuses on subjective (as opposed to factual) questions and answers. The dataset consists of roughly 10,000 questions over reviews from 6 different domains: books, movies, grocery, electronics, TripAdvisor (i.e. hotels), and restaurants. Each question is paired with a review and a span is highlighted as the answer to the question (with some questions having no answer). Moreover, both questions and answer spans are assigned a subjectivity label by annotators. Questions such as \"How much does this product weigh?\" is a factual question (i.e., low subjectivity), while \"Is this easy to use?\" is a subjective question (i.e., high subjectivity).\n",
    ">\n",
    "> In short, SubjQA provides a setting to study how well extractive QA systems perform on finding answer that are less factual and to what extent modeling subjectivity can improve the performance of QA systems.\n",
    "\n",
    "Let's download the `subjqa` dataset and poke around a bit.\n",
    "\n",
    "See the [Dataset card fof `subjqa` at HF](https://huggingface.co/datasets/subjqa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35ee076-23ff-46ce-b594-490f40c7191d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['books', 'electronics', 'grocery', 'movies', 'restaurants', 'tripadvisor']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "domains = get_dataset_config_names(\"subjqa\")\n",
    "domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96afa77f-bfe1-4b5c-8b7e-7d176c339f59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset subjqa (/home/kashiwapoodle/.cache/huggingface/datasets/subjqa/electronics/1.1.0/2c12e496c4c675ab4a57ffb5d3f538f2e7b89793956e50da37126393ce23b6c6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dfdb1a85264189b34c489c5b61d7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train': (1295, 15), 'test': (358, 15), 'validation': (255, 15)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "subjqa = load_dataset(\"subjqa\", name=\"electronics\")\n",
    "subjqa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10d71b3-b73f-45ed-a0cc-b2a031428309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"domain\": \"electronics\",\n",
      "  \"nn_mod\": \"harsh\",\n",
      "  \"nn_asp\": \"high\",\n",
      "  \"query_mod\": \"not strong\",\n",
      "  \"query_asp\": \"bass\",\n",
      "  \"q_reviews_id\": \"7c46670208f7bf5497480fbdbb44561a\",\n",
      "  \"question_subj_level\": 1,\n",
      "  \"ques_subj_score\": 0.5,\n",
      "  \"is_ques_subjective\": false,\n",
      "  \"review_id\": \"ce76793f036494eabe07b33a9a67288a\",\n",
      "  \"id\": \"d476830bf9282e2b9033e2bb44bbb995\",\n",
      "  \"title\": \"B00001P4ZH\",\n",
      "  \"context\": \"To anyone who hasn't tried all the various types of headphones, it is important to remember exactly what these are: cheap portable on-ear headphones. They give a totally different sound then in-ears or closed design phones, but for what they are I would say they're good. I currently own six pairs of phones, from stock apple earbuds to Sennheiser HD 518s. Gave my Portapros a run on both my computer's sound card and mp3 player, using 256 kbps mp3s or better. The clarity is good and they're very lightweight. The folding design is simple but effective. The look is certainly retro and unique, although I didn't find it as comfortable as many have claimed. Earpads are *very* thin and made my ears sore after 30 minutes of listening, although this can be remedied to a point by adjusting the \\\"comfort zone\\\" feature (tightening the temple pads while loosening the ear pads). The cord seems to be an average thickness, but I wouldn't get too rough with these. The steel headband adjusts smoothly and easily, just watch out that the slider doesn't catch your hair. Despite the sore ears, the phones are very lightweight overall.Back to the sound: as you would expect, it's good for a portable phone, but hardly earth shattering. At flat EQ the clarity is good, although the highs can sometimes be harsh. Bass is weak as expected, even with EQ adjusted up. To be fair, a portable on-ear would have a tough time comparing to the bass of an in-ear with a good seal or a pair with larger drivers. No sound isolation offered if you're into that sort of thing. Cool 80s phones, though I've certainly owned better portable on-ears (Sony makes excellent phones in this category). Soundstage is very narrow and lacks body. A good value if you can get them for under thirty, otherwise I'd rather invest in a nicer pair of phones. If we're talking about value, they're a good buy compared to new stock apple buds. If you're trying to compare the sound quality of this product to serious headphones, there's really no comparison at all.Update: After 100 hours of burn-in time the sound has not been affected in any appreciable way. Highs are still harsh, and bass is still underwhelming. I sometimes use these as a convenience but they have been largely replaced in my collection.\",\n",
      "  \"question\": \"Is this music song have a goo bass?\",\n",
      "  \"answers\": {\n",
      "    \"text\": [\n",
      "      \"Bass is weak as expected\",\n",
      "      \"Bass is weak as expected, even with EQ adjusted up\"\n",
      "    ],\n",
      "    \"answer_start\": [\n",
      "      1302,\n",
      "      1302\n",
      "    ],\n",
      "    \"answer_subj_level\": [\n",
      "      1,\n",
      "      1\n",
      "    ],\n",
      "    \"ans_subj_score\": [\n",
      "      0.5083333253860474,\n",
      "      0.5083333253860474\n",
      "    ],\n",
      "    \"is_ans_subjective\": [\n",
      "      true,\n",
      "      true\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#print(subjqa[\"train\"][\"answers\"][1])\n",
    "print(json.dumps(\n",
    "    subjqa[\"train\"][1], \n",
    "    indent=2\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3710f341-d76d-43f5-833a-cf2612a58c9a",
   "metadata": {},
   "source": [
    "You see how `answers` has children `text`, `answer_start`, `answer_subj_level`, etc. \n",
    "\n",
    "If you want to explode the children of `answers` into their own columns, then use [`datasets.flatten`](https://huggingface.co/docs/datasets/process#flatten):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4201c0c-de3f-4b78-90d1-193288e00654",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'domain': {'dtype': 'string', '_type': 'Value'},\n",
       " 'nn_mod': {'dtype': 'string', '_type': 'Value'},\n",
       " 'nn_asp': {'dtype': 'string', '_type': 'Value'},\n",
       " 'query_mod': {'dtype': 'string', '_type': 'Value'},\n",
       " 'query_asp': {'dtype': 'string', '_type': 'Value'},\n",
       " 'q_reviews_id': {'dtype': 'string', '_type': 'Value'},\n",
       " 'question_subj_level': {'dtype': 'int64', '_type': 'Value'},\n",
       " 'ques_subj_score': {'dtype': 'float32', '_type': 'Value'},\n",
       " 'is_ques_subjective': {'dtype': 'bool', '_type': 'Value'},\n",
       " 'review_id': {'dtype': 'string', '_type': 'Value'},\n",
       " 'id': {'dtype': 'string', '_type': 'Value'},\n",
       " 'title': {'dtype': 'string', '_type': 'Value'},\n",
       " 'context': {'dtype': 'string', '_type': 'Value'},\n",
       " 'question': {'dtype': 'string', '_type': 'Value'},\n",
       " 'answers.text': {'feature': {'dtype': 'string', '_type': 'Value'},\n",
       "  '_type': 'Sequence'},\n",
       " 'answers.answer_start': {'feature': {'dtype': 'int32', '_type': 'Value'},\n",
       "  '_type': 'Sequence'},\n",
       " 'answers.answer_subj_level': {'feature': {'dtype': 'int64', '_type': 'Value'},\n",
       "  '_type': 'Sequence'},\n",
       " 'answers.ans_subj_score': {'feature': {'dtype': 'float32', '_type': 'Value'},\n",
       "  '_type': 'Sequence'},\n",
       " 'answers.is_ans_subjective': {'feature': {'dtype': 'bool', '_type': 'Value'},\n",
       "  '_type': 'Sequence'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjqa[\"validation\"].flatten().features.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da513598-7f62-4c46-88a2-f03d0e83b0b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions in train: 1295\n",
      "Number of questions in test: 358\n",
      "Number of questions in validation: 255\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = { \n",
    "    split: dset.to_pandas() \n",
    "    for split, dset \n",
    "    in subjqa.flatten().items() \n",
    "}\n",
    "\n",
    "for split, df in dfs.items():\n",
    "    print(f\"Number of questions in {split}: {df['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d2e70-dd76-465b-823c-4ac047c94a62",
   "metadata": {},
   "source": [
    "Note that the `subjqa` dataset is quite small, but entirely in keeping with real-world scenarios since labelled data is very hard to find and expensive to create (you should know that!).\n",
    "\n",
    "Now that we have transformed the `dataset` into `pandas.DataFrame`, we can use things like [`sample`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) to have a closer look..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24aede2e-873a-45b9-9495-ac4699e70f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>answers.text</th>\n",
       "      <th>answers.answer_start</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>B005DKZTMG</td>\n",
       "      <td>Does the keyboard lightweight?</td>\n",
       "      <td>[this keyboard is compact]</td>\n",
       "      <td>[215]</td>\n",
       "      <td>I really like this keyboard.  I give it 4 star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>B00AAIPT76</td>\n",
       "      <td>How is the battery?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I bought this after the first spare gopro batt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                        question                answers.text   \n",
       "791   B005DKZTMG  Does the keyboard lightweight?  [this keyboard is compact]  \\\n",
       "1159  B00AAIPT76             How is the battery?                          []   \n",
       "\n",
       "     answers.answer_start                                            context  \n",
       "791                 [215]  I really like this keyboard.  I give it 4 star...  \n",
       "1159                   []  I bought this after the first spare gopro batt...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_cols = [\n",
    "    \"title\",\n",
    "    \"question\",\n",
    "    \"answers.text\",\n",
    "    \"answers.answer_start\",\n",
    "    \"context\"\n",
    "]\n",
    "\n",
    "sample_df = dfs[\"train\"][qa_cols].sample(2, random_state=7)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b812ced-00ea-4277-b815-6c3b66edd34c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this keyboard is compact'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx = sample_df[\"answers.answer_start\"].iloc[0][0]\n",
    "end_idx = start_idx + len(sample_df[\"answers.text\"].iloc[0][0])\n",
    "sample_df[\"context\"].iloc[0][start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb0c8e7-246a-4165-a771-08bc1f26631c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = {}\n",
    "\n",
    "question_types = [\n",
    "    \"What\",\n",
    "    \"How\",\n",
    "    \"Is\",\n",
    "    \"Does\",\n",
    "    \"Do\",\n",
    "    \"Was\",\n",
    "    \"Where\",\n",
    "    \"Why\"\n",
    "]\n",
    "\n",
    "for q in question_types:\n",
    "    counts[q] = dfs[\"train\"][\"question\"].str.startswith(q).value_counts()[True]\n",
    "\n",
    "pd.Series(counts).sort_values().plot.barh()\n",
    "plt.title(\"Frequency of Question Types\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b698a5b-a931-4a74-9775-1c847e87f454",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is the camera?\n",
      "How do you like the control?\n",
      "How fast is the charger?\n",
      "What is direction?\n",
      "What is the quality of the construction of the bag?\n",
      "What is your impression of the product?\n",
      "Is this how zoom works?\n",
      "Is sound clear?\n",
      "Is it a wireless keyboard?\n"
     ]
    }
   ],
   "source": [
    "for question_type in [\"How\", \"What\", \"Is\"]:\n",
    "    for question in (\n",
    "        dfs[\"train\"][dfs[\"train\"].question.str.startswith(question_type)]\n",
    "        .sample(n=3, random_state=42)[\"question\"]\n",
    "    ):\n",
    "        print(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30cef7-ca37-44c1-a916-7387c24fd5c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extracting Answers from Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a090962f-9481-4dfe-a994-678c15d9a2b7",
   "metadata": {},
   "source": [
    "On SQuAD2.0:\n",
    "\n",
    "> Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuAD 2.0, the latest version of the Stanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD 1.1 achieves only 66% F1 on SQuAD 2.0. \n",
    "\n",
    "Suggested reading:\n",
    "* [SQuAD2.0 - The Stanford Question Answering Dataset](https://rajpurkar.github.io/SQuAD-explorer/)\n",
    "* [Know What You Don't Know: Unanswerable Questions for SQuAD]() by Rajpurkar, Jia, and Liang, 2018\n",
    "* [Question Answering on SQuAD2.0](https://paperswithcode.com/sota/question-answering-on-squad20) on paperswithcode.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3422a8e2-3241-49e1-ace4-b581abb1571f",
   "metadata": {},
   "source": [
    "### Tokening text for QA\n",
    "\n",
    "* Training dataset is small, with only 1295 examples.\n",
    "* Since the structure of the labels for QA (predicting the start/end of an answer span) should be the same across datasets, starting from a fine-tuned, large-scale QA model is the sane approach.\n",
    "\n",
    "We will use [`deepset/minilm-uncased-squad2`](https://huggingface.co/deepset/minilm-uncased-squad2#minilm-l12-h384-uncased-for-qa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5ef0529-b409-4352-8554-bb9c295b7107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d891906b-ff0f-4e9f-94f9-866c034f773d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"How much music can this hold?\"\n",
    "context = \"\"\"An MP3 is about 1 MG/minute, so about 6000 hours depending on file size.\"\"\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da125ce2-3b4e-411c-84b9-55569ea3579b",
   "metadata": {},
   "source": [
    "`inputs` has `input_ids` and `attention_mask` as expected, but notice how `token_type_id` indicate `0` for question token and `1` for context token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71a2b55d-4776-4a79-b07e-502a5799525c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_ids</th>\n",
       "      <td>101</td>\n",
       "      <td>2129</td>\n",
       "      <td>2172</td>\n",
       "      <td>2189</td>\n",
       "      <td>2064</td>\n",
       "      <td>2023</td>\n",
       "      <td>2907</td>\n",
       "      <td>1029</td>\n",
       "      <td>102</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td>2061</td>\n",
       "      <td>2055</td>\n",
       "      <td>25961</td>\n",
       "      <td>2847</td>\n",
       "      <td>5834</td>\n",
       "      <td>2006</td>\n",
       "      <td>5371</td>\n",
       "      <td>2946</td>\n",
       "      <td>1012</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_type_ids</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attention_mask</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0     1     2     3     4     5     6     7    8     9   ...   \n",
       "input_ids       101  2129  2172  2189  2064  2023  2907  1029  102  2019  ...  \\\n",
       "token_type_ids    0     0     0     0     0     0     0     0    0     1  ...   \n",
       "attention_mask    1     1     1     1     1     1     1     1    1     1  ...   \n",
       "\n",
       "                  18    19     20    21    22    23    24    25    26   27  \n",
       "input_ids       2061  2055  25961  2847  5834  2006  5371  2946  1012  102  \n",
       "token_type_ids     1     1      1     1     1     1     1     1     1    1  \n",
       "attention_mask     1     1      1     1     1     1     1     1     1    1  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    dict(\n",
    "        (k, v.tolist()[0]) \n",
    "        for k,v in inputs.items()\n",
    "    )\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13ade2f8-a930-475e-9c2d-72e3e53f94e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] how much music can this hold? [SEP] an mp3 is about 1 mg / minute, so about 6000 hours depending on file size. [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(inputs[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "661a1abb-88d4-480e-a5e9-73b5b2af3d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-1.1286, -4.7415, -5.3876, -5.2379, -5.2723, -5.5013, -4.9711, -6.1821,\n",
      "         -1.1286, -0.0502, -0.3999, -1.9431,  3.2140,  4.1175, -1.1694, -3.8895,\n",
      "         -2.1539, -4.5801, -1.3942,  4.1694,  5.3227, -0.0295, -3.0786, -4.8637,\n",
      "         -2.3779, -3.5348, -3.5455, -1.1286]]), end_logits=tensor([[-1.0579, -5.4757, -5.0125, -5.1458, -5.4216, -5.4915, -5.1583, -4.5826,\n",
      "         -1.0580, -3.8277, -1.1060, -3.8418, -3.2789, -1.2299, -0.9271, -3.3560,\n",
      "          4.1270,  0.2892, -3.2542, -3.1378,  1.0524,  5.8469, -0.2193, -4.8842,\n",
      "         -3.3028, -0.1381,  1.6563, -1.0579]]), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5fec1108-13e9-4761-8b76-891ebef5c74c",
   "metadata": {
    "tags": []
   },
   "source": [
    "dir(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c072441d-f357-4dc4-bbf9-8bf2a92c4e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed755315-293b-489f-93ae-c4e3a2a3249f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([1, 28])\n",
      "Start logits shape: torch.Size([1, 28])\n",
      "End logits shape: torch.Size([1, 28])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input IDs shape: {inputs.input_ids.size()}\")\n",
    "print(f\"Start logits shape: {start_logits.size()}\")\n",
    "print(f\"End logits shape: {end_logits.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0c042bd-db21-4d50-b12c-53dd0488f50a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How much music can this hold?\n",
      "Answer: 6000 hours\n"
     ]
    }
   ],
   "source": [
    "start_idx = torch.argmax(start_logits)\n",
    "end_idx = torch.argmax(end_logits) + 1\n",
    "\n",
    "answer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n",
    "answer = tokenizer.decode(answer_span)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec206b27-4f52-4382-9490-4a50a18dc0de",
   "metadata": {},
   "source": [
    "... and the same as above, but now wrapped in an HF `pipeline`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ec113c0-d8b9-4846-9634-51470540f28e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/transformers-py38/lib/python3.8/site-packages/transformers/pipelines/question_answering.py:323: UserWarning: topk parameter is deprecated, use top_k instead\n",
      "  warnings.warn(\"topk parameter is deprecated, use top_k instead\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.46839281916618347,\n",
       "  'start': 38,\n",
       "  'end': 48,\n",
       "  'answer': '6000 hours'},\n",
       " {'score': 0.14781419932842255,\n",
       "  'start': 32,\n",
       "  'end': 48,\n",
       "  'answer': 'about 6000 hours'},\n",
       " {'score': 0.14034153521060944,\n",
       "  'start': 16,\n",
       "  'end': 48,\n",
       "  'answer': '1 MG/minute, so about 6000 hours'},\n",
       " {'score': 0.05686337128281593,\n",
       "  'start': 10,\n",
       "  'end': 48,\n",
       "  'answer': 'about 1 MG/minute, so about 6000 hours'},\n",
       " {'score': 0.02513236179947853,\n",
       "  'start': 16,\n",
       "  'end': 27,\n",
       "  'answer': '1 MG/minute'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "pipe(\n",
    "    question=question, \n",
    "    context=context, \n",
    "    topk=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd6557-8ef5-4ae9-8603-89c54766f71b",
   "metadata": {},
   "source": [
    "In the case of a question for which no answer is possble, this model will assign a high start and end score to the `[CLS]` token, mapping the output to the empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12f7fb19-222c-4bd2-97ca-f38ee37badba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9904054999351501, 'start': 0, 'end': 0, 'answer': ''}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\n",
    "    question=\"How many roads must a man walk?\",\n",
    "    context=context,\n",
    "    handle_impossible_answer=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e0691c-ac98-4485-9c1c-f14141c59ca5",
   "metadata": {},
   "source": [
    "### Dealing with long passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b15325a-bc5c-41d4-bcdc-b3f32dcca6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "example = dfs[\"train\"].iloc[0][[\"question\", \"context\"]]\n",
    "\n",
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    return_overflowing_tokens=True,\n",
    "    max_length=100,\n",
    "    stride=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a03f465a-01f7-47f2-9e42-8835bda4f233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window #0 has 100 tokens\n",
      "Window #1 has 88 tokens\n"
     ]
    }
   ],
   "source": [
    "for idx, window in enumerate(tokenized_example[\"input_ids\"]):\n",
    "    print(f\"Window #{idx} has {len(window)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebbf4b2a-17a7-4823-ae41-1a35e80c8af7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2129, 2003, 1996, 3321, 1029, 102, 1045, 2031, 2018, 12849, 4757, 2132, 19093, 1999, 1996, 2627, 1010, 4013, 26424, 2050, 1998, 1053, 2480, 1011, 5585, 1012, 1996, 12849, 4757, 3417, 9331, 3217, 2003, 12109, 1998, 2038, 2307, 3321, 3433, 1012, 1996, 2147, 2307, 2007, 2026, 11924, 3042, 1998, 2064, 2022, 1000, 4565, 2039, 1000, 2000, 2022, 3344, 1999, 2026, 9055, 6598, 2030, 3274, 4524, 2302, 2893, 24514, 2098, 1012, 2027, 2024, 2200, 2422, 1998, 2079, 2025, 2514, 3082, 2030, 4562, 2091, 2006, 2115, 5551, 2130, 2044, 5962, 2000, 2189, 2007, 2068, 2006, 2035, 2154, 1012, 1996, 2614, 2003, 102]\n",
      "[101, 2129, 2003, 1996, 3321, 1029, 102, 1998, 2079, 2025, 2514, 3082, 2030, 4562, 2091, 2006, 2115, 5551, 2130, 2044, 5962, 2000, 2189, 2007, 2068, 2006, 2035, 2154, 1012, 1996, 2614, 2003, 2305, 1998, 2154, 2488, 2084, 2151, 4540, 1011, 13007, 2071, 2022, 1998, 2024, 2471, 2004, 2204, 2004, 1996, 4013, 26424, 2050, 1012, 2027, 2024, 1000, 2330, 2250, 1000, 2132, 19093, 2061, 2017, 3685, 2674, 1996, 3321, 2000, 1996, 10203, 4127, 1010, 2021, 2009, 3310, 2485, 1012, 2005, 1002, 3590, 1010, 2017, 3685, 2175, 3308, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "for window in tokenized_example[\"input_ids\"]:\n",
    "    print(f\"{window}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09591e9f-550a-4ee4-81fd-17e5ecbbb878",
   "metadata": {},
   "source": [
    "To clarify, here is are the first 75 tokens of the 100 tokens that make up the first window; along with the trailing 25 tokens that make up the stride (overlap). Tokens have been decoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e957060-9aed-4dda-aab0-fd9ce92a185b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens 0 through 74 for window 0\n",
      "=====\n",
      "i have had koss headphones in the past, pro 4aa and qz - 99. the koss portapro is portable and has great bass response. the work great with my android phone and can be \" rolled up \" to be carried in my motorcycle jacket or computer bag without getting crunched. they are very light\n",
      "\n",
      "... and the last 25 tokens for window 0 making up the stride:\n",
      "=====\n",
      "and do not feel heavy or bear down on your ears even after listening to music with them on all day. the sound is [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokens 0 through 74 for window 0\\n=====\\n{tokenizer.decode(tokenized_example['input_ids'][0][7:-26])}\")\n",
    "print()\n",
    "print(f\"... and the last 25 tokens for window 0 making up the stride:\\n=====\\n{tokenizer.decode(tokenized_example['input_ids'][0][-26:])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c61e03b-9d42-45c5-b1e8-156a6be5b548",
   "metadata": {
    "tags": []
   },
   "source": [
    "And here is what window 1 looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d3698b4-d416-403a-a974-37a270475992",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens 0 through 25 for the stride (overlapping) input continuation in window 1\n",
      "=====\n",
      "and do not feel heavy or bear down on your ears even after listening to music with them on all day. the sound is\n",
      "\n",
      "... and the trailing remaining tokens for window 1\n",
      "=====\n",
      "night and day better than any ear - bud could be and are almost as good as the pro 4aa. they are \" open air \" headphones so you cannot match the bass to the sealed types, but it comes close. for $ 32, you cannot go wrong. [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokens 0 through 25 for the stride (overlapping) input continuation in window 1\\n=====\\n{tokenizer.decode(tokenized_example['input_ids'][1][7:7+25])}\")\n",
    "print()\n",
    "print(f\"... and the trailing remaining tokens for window 1\\n=====\\n{tokenizer.decode(tokenized_example['input_ids'][1][7+25:])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb06d1-b93b-4753-9e21-cece3b5b0e32",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda1d32-67b8-41a1-8de6-47e22614d58c",
   "metadata": {},
   "source": [
    "### Using Haystack to Build a QA Pipeline\n",
    "\n",
    "_WARNING!!! Apparently the farm-haystack API has change since the writing of this book!_\n",
    "\n",
    "While referring to the Basic Install procedures per [Quick Start on haystack.deepset.ai](https://haystack.deepset.ai/overview/quick-start) and [Tutorial: Build Your First Question Answering System](https://haystack.deepset.ai/tutorials/01_basic_qa_pipeline) on the Haystack by deepset website, we will make appropriate changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60901005-b817-46eb-8a1c-e0a67e8fd9e7",
   "metadata": {},
   "source": [
    "#### Installing `farm-haystack`\n",
    "\n",
    "This part will require the installation of `farm-haystack` (NOT to be confused with `haystack`!).\n",
    "\n",
    "    pip install farm-haystack\n",
    "    \n",
    "    pip install 'farm-haystack[elasticsearch]' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02d8f66f-fc66-41ef-a683-02c412112c94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from subprocess import Popen, PIPE, STDOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93bf4db-6f21-4af5-8dff-238d58bff176",
   "metadata": {},
   "source": [
    "#### Installing ElasticSearch\n",
    "\n",
    "* The following code block downloads and install `elasticsearch`.\n",
    "* This bit needs to be done only _once_!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8ddc22f-ee82-453b-966a-dadc01d5a22a",
   "metadata": {
    "tags": []
   },
   "source": [
    "url = \"https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz\"\n",
    "\n",
    "!wget -nc -q {url}\n",
    "\n",
    "!tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604bdd9f-164d-47e7-a5f9-9d2359aa2c33",
   "metadata": {},
   "source": [
    "#### Start `elasticsearch` server\n",
    "\n",
    "Execute the following code block to start up `elasticsearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a10a7b68-9bde-4a42-9231-6b3b95d0cea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this will start up elasticsearch and create a PID file...\n",
    "es_server = Popen(\n",
    "    args=[\"elasticsearch-7.9.2/bin/elasticsearch\", \"-p\", \"pidfile\"],\n",
    "    stdout=PIPE,\n",
    "    stderr=STDOUT\n",
    ")\n",
    "\n",
    "# wait until Elasticsearch has started..\n",
    "!sleep 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda42f3c-e2e7-473a-a993-b87ba8702e54",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### `curl` call to check `elasticsearch` server status\n",
    "\n",
    "This `curl` call can be used to check if `elasticsearch` is running or not..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e80e569-27c3-4d2b-bf4f-e43a193d8591",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"t4-us-central1-f\",\n",
      "  \"cluster_name\" : \"elasticsearch\",\n",
      "  \"cluster_uuid\" : \"dwBITPl8QwS5wtWeKRNKow\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"7.9.2\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"tar\",\n",
      "    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n",
      "    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"8.6.2\",\n",
      "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X GET \"localhost:9200/?pretty\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ff636-fdc3-4b61-b412-d1430cdfe06b",
   "metadata": {},
   "source": [
    "#### Stop `elasticsearch` server\n",
    "\n",
    "Execute the following code block to stop `elasticsearch`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b12586a3-e08f-4e90-998f-d6b125d020a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "pidfile = Path(os.getcwd()) / Path(\"elasticsearch-7.9.2/pidfile\")\n",
    "\n",
    "pid = pidfile.read_text()\n",
    "\n",
    "stop_server = Popen(\n",
    "    args=[\"kill\", \"-15\", pid],\n",
    "    stdout=PIPE,\n",
    "    stderr=STDOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f87205-46b9-4bc7-b26d-75d98468c989",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46692051-4fc3-4656-949a-8319a3050702",
   "metadata": {},
   "source": [
    "### Instatiate a document store"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03f242c2-90bd-4859-a0c0-0dda5568af4a",
   "metadata": {},
   "source": [
    "# code on page 184, Ch. 7 is outdated!\n",
    "from haystack.documentstore.elasticsearch import ElasticsearchDocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ead7804-1daf-4383-b931-adc6ec2aad9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "# return the document embedding for later use with dense retriever\n",
    "#                                                  ^^^^^\n",
    "document_store = ElasticsearchDocumentStore(return_embedding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c06cdef0-ec8b-4b31-905c-3d3e3dc0f8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1615 documents\n"
     ]
    }
   ],
   "source": [
    "for split, df in dfs.items():\n",
    "    # exclude duplicate reviews\n",
    "    docs = [{\n",
    "        \"content\": row[\"context\"],\n",
    "        \"meta\": {\n",
    "            \"item_id\": row[\"title\"],\n",
    "            \"question_id\": row[\"id\"],\n",
    "            \"split\": split}}\n",
    "        for _,row in df.drop_duplicates(subset=\"context\").iterrows()]\n",
    "    document_store.write_documents(docs, index=\"document\")\n",
    "    \n",
    "print(f\"Loaded {document_store.get_document_count()} documents\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6441b5-b201-4006-b7c2-97da8c2df7b1",
   "metadata": {},
   "source": [
    "### Initializing a retriever"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6ea38c4-c4b7-4878-9897-613c3ed6e392",
   "metadata": {},
   "source": [
    "# code on Ch. 7, page 186 is outdated!\n",
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "\n",
    "es_retriever = ElasticsearchRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09cde23e-e231-4d63-85ab-8f685bf809ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from haystack.nodes import BM25Retriever\n",
    "\n",
    "retriever = BM25Retriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24f2f474-6347-449e-b91b-a31d659da857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_id = \"B0074BW614\"\n",
    "query = \"Is it good for reading?\"\n",
    "\n",
    "retrieved_docs = retriever.retrieve(\n",
    "    query=query,\n",
    "    top_k=3,\n",
    "    filters={\n",
    "        \"item_id\": item_id,\n",
    "        \"split\": [\"train\"]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f03231a-91be-49a2-97b6-3e72481c7801",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document: id=252e83e25d52df7311d597dc89eef9f6, content='This is a gift to myself.  I have been a kindle user for 4 years and this is my third one.  I never ...'>\n",
      "\n",
      "<class 'haystack.schema.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[0])\n",
    "print()\n",
    "print(type(retrieved_docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a109864-491d-4843-818c-bd2715e07cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'This is a gift to myself.  I have been a kindle user for 4 years and this is my third one.  I never thought I would want a fire for I mainly use it for book reading.  I decided to try the fire for when I travel I take my laptop, my phone and my iPod classic.  I love my iPod but watching movies on the plane with it can be challenging because it is so small. Laptops battery life is not as good as the Kindle.  So the Fire combines for me what I needed all three to do. So far so good.', 'content_type': 'text', 'score': 0.6857824513476455, 'meta': {'item_id': 'B0074BW614', 'question_id': '868e311275e26dbafe5af70774a300f3', 'split': 'train'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '252e83e25d52df7311d597dc89eef9f6'}\n"
     ]
    }
   ],
   "source": [
    "doc = retrieved_docs[0]\n",
    "print(doc.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f83f3-5816-4458-b44c-a66c744b48bc",
   "metadata": {},
   "source": [
    "#### Initializing a reader\n",
    "\n",
    "> A Reader scans the texts it received from the Retriever and extracts the top answer candidates. Readers are based on powerful deep learning models but are much slower than Retrievers at processing the same amount of text.\n",
    "> <br/>... from [Tutorial: Build Your First Question Answering System](https://haystack.deepset.ai/tutorials/01_basic_qa_pipeline)\n",
    "> <br/><br/>MiniLM\n",
    "> <br/>A distilled model that sacrifices a little accuracy for speed.\n",
    "> <br/>Pro: 40% smaller, 50% faster inference speed, and better accuracy than BERT base.\n",
    "> <br/>Con: Still doesn’t match the best base-sized models in accuracy.\n",
    "> <br/>... from [Models, Haystack documentation](https://docs.haystack.deepset.ai/docs/reader#models)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ba6089c-dfeb-43c6-b372-403ae55bbfe6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# code on page 187, Ch. 7 is outdated!\n",
    "from haystack.reader.farm import FarmReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a34223ef-79b4-48bd-baf6-1ba23f14947a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from haystack.nodes import FARMReader\n",
    "\n",
    "model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
    "max_seq_len, doc_stride = 384, 128\n",
    "\n",
    "reader = FARMReader(\n",
    "    model_name_or_path=\"deepset/roberta-base-squad2\", \n",
    "    progress_bar=False,\n",
    "    max_seq_len=max_seq_len,\n",
    "    doc_stride=doc_stride,\n",
    "    return_no_answer=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36b9b567-7322-441c-b206-0a90d0357ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'How much music can this hold?', 'no_ans_gap': 3.9765353202819824, 'answers': [<Answer {'answer': '', 'type': 'extractive', 'score': 0.570759527304695, 'context': None, 'offsets_in_document': [{'start': 0, 'end': 0}], 'offsets_in_context': [{'start': 0, 'end': 0}], 'document_ids': None, 'meta': {}}>]}\n"
     ]
    }
   ],
   "source": [
    "print(reader.predict_on_texts(question=question, texts=[context], top_k=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6db7f1-feb1-426d-ab28-e0fe0178dbd8",
   "metadata": {},
   "source": [
    "#### Putting it all together\n",
    "\n",
    "The API for `ExtractiveQAPipeline` appears to have changed drastically:\n",
    "\n",
    "* `top_k_retrievers` is gone as direct parameter; use `params` and `Retriever` node name\n",
    "* `top_k_readers` is gone as direct parameter; use `params` and `Reader` node name\n",
    "* `filters` s gone as direct parameter; [use `params` and `filters` to filter results by using `meta` fields](https://docs.haystack.deepset.ai/docs/metadata-filtering#basic-filters)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1093ac30-7988-4e74-b2a5-afb8309b19c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# code on page 188, Ch. 7 is outdated!\n",
    "from haystack.pipeline import ExtractiveQAPipeline\n",
    "\n",
    "...\n",
    "\n",
    "preds = pipe.run(\n",
    "    query=query,\n",
    "    top_k_retrievers=3,\n",
    "    top_k_readers=n_answers,\n",
    "    filters={\n",
    "        \"item_id\": item_id,\n",
    "        \"split\": [\"train\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7ea0e4f-f229-4a53-a33b-64bdbb16b3ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "\n",
    "pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2e87ed1-a7d6-4d40-a940-fb66b26ab365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_answers = 3\n",
    "\n",
    "preds = pipe.run(\n",
    "    query=query,\n",
    "    params={\n",
    "        \"filters\": {\n",
    "            \"item_id\": item_id,\n",
    "            \"split\": [\"train\"]\n",
    "        },\n",
    "        \"Retriever\": {\"top_k\": 3},\n",
    "    },\n",
    ")\n",
    "\n",
    "answers = [ans for ans in preds['answers'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "344589ed-e534-4c5f-87aa-4f5e315ef15e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is it good for reading?\n",
      "\n",
      "Answer 1: \n",
      "Review snippet: ...None\n",
      "\n",
      "Answer 2: it is great for reading books\n",
      "Review snippet: ...myself after becoming addicted to hers! Our son LOVES it and it is great for reading books when no light is available. Amazing sound but I suggest goo\n",
      "\n",
      "Answer 3: It's light enough that I can hold it to read, but the larger screen compared to the Kindle makes for easier reading\n",
      "Review snippet: ...t perfect for me. It's light enough that I can hold it to read, but the larger screen compared to the Kindle makes for easier reading. I love the colo\n",
      "\n",
      "Answer 4: I mainly use it for book reading\n",
      "Review snippet: ... is my third one.  I never thought I would want a fire for I mainly use it for book reading.  I decided to try the fire for when I travel I take my la\n",
      "\n",
      "Answer 5: the larger screen compared to the Kindle makes for easier reading\n",
      "Review snippet: ...ght enough that I can hold it to read, but the larger screen compared to the Kindle makes for easier reading. I love the color, something I never thou\n",
      "\n",
      "Answer 6: I simply can't hold the Kindle Fire long enough for reading\n",
      "Review snippet: ...r short periods to play a few games. However, I simply can't hold the Kindle Fire long enough for reading. This won't be an issue for most people, but\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question: {preds['query']}\\n\")\n",
    "\n",
    "for i,answer in enumerate(answers):\n",
    "    print(f\"Answer {i+1}: {answer.answer}\")\n",
    "    print(f\"Review snippet: ...{answer.context}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ffec9-1c4d-416d-94d7-4e99b9f780ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating the Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b7fc68d-2270-4d3d-8dfb-0756faa10703",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'haystack.pipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'haystack.pipeline'"
     ]
    }
   ],
   "source": [
    "from haystack.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c27a8fcc-c726-4aad-bfaf-909b5a85ede5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'haystack.eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvalDocuments\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'haystack.eval'"
     ]
    }
   ],
   "source": [
    "from haystack.eval import EvalDocuments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef6da75-2ee2-4cc4-a0d6-34ce0ee62b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
