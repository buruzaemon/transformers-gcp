{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37bed5f6-166b-434e-ac4c-efee0dfa07e6",
   "metadata": {},
   "source": [
    "# Making Transformers Efficient in Production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597880b-f340-404f-9502-cc0770d6ee86",
   "metadata": {},
   "source": [
    "#### ?\n",
    "\n",
    "> (W)hen developing a new machine learning model for your business, do you first make it accurate, then worry about making it fast in production? Or do you first make sure it can be fast, then make it accurate? \n",
    "> <p/>\n",
    "> ...\n",
    "> <p/>\n",
    "> While this was a stressful experience for us, it doesnâ€™t have to be for you, because in this article we are going to share the optimizations that made Bert inference fast for us. So you can start with an egg (a known playbook for making certain Bert models fast in production), then focus on the chicken (making your Bert model accurate).\n",
    "\n",
    "* Blogpost@Robolox: [How We Scaled BERT to Serve 1+ Billion Daily Requests on CPUs](https://medium.com/@quocnle/how-we-scaled-bert-to-serve-1-billion-daily-requests-on-cpus-d99be090db26)\n",
    "* And the [video from Databricks on YouTube](https://youtu.be/Nw77sEAn_Js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32297170-ec80-4971-b5d8-854a0e404fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
