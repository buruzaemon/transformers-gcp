{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8d0df5-44b3-4d97-984e-3fcccc5fd386",
   "metadata": {},
   "source": [
    "# Chapter 4: Multilingual Named Entity Recognition\n",
    "\n",
    "## On Fine-tuning ... to perform token classification (NER)\n",
    "\n",
    "### General workflow\n",
    "\n",
    "The workflow for the task of fine-tuning an existing model for token classfication can be broken down into for major tasks:\n",
    "\n",
    "* preparing a dataset for fine-tuning\n",
    "* preparing an appropriate head and configuration to use over the existing model\n",
    "* prepare performance metrics, training arguments, and a data collator\n",
    "* lastly, train your model and evaluate the results\n",
    "\n",
    "#### Prepare dataset\n",
    "\n",
    "1. Obtain a dataset.\n",
    "\n",
    "1. Add any neccessary features to the dataset(s) required for token classification. In the case of NER and our dataset, the `ner_tags` feature have values that are `int` indicating the class. Since we would like to use the IOB2 format, we use `map()` and `ClassLabel.int2str()` to add another dataset feature containing the IOB2 tag strings corresponding to the `ner_tags` class `int` value.\n",
    "\n",
    "1. Tokenize the training dataset according to your needs. _Make sure you have an appropriate tokenizer!_\n",
    "\n",
    "\n",
    "#### Prepare custom model head that wraps an existing base model\n",
    "\n",
    "1. Create a custom model for token classification. Ideally, this should wrap an existing base model and use the logits of that to classify the named entity tokens. In our case, we extend `transformers.models.roberta.modeling_roberta.RobertaPretrainedModel`, implementing `__init__` and `forward`.\n",
    "\n",
    "1. Prepare a corresponding configuration object for our model. We can leverage [`transformer.AutoConfig.from_pretrained`](https://huggingface.co/docs/transformers/v4.26.1/en/model_doc/auto#transformers.AutoConfig.from_pretrained), passing in the model's name, the `num_labels` for the number of NER types (classes), and dictionaries mapping `id2label` and `label2id`.\n",
    "\n",
    "1. Test this model and configuration on an example input.\n",
    "\n",
    "\n",
    "#### Prepare for fine-tuning\n",
    "\n",
    "1. Prepare performance metrics.\n",
    "\n",
    "1. Prepare training arguments\n",
    "\n",
    "1. Prepare data collator\n",
    "\n",
    "\n",
    "#### Train and review metrics\n",
    "\n",
    "1. Train\n",
    "\n",
    "1. Review metrics\n",
    "\n",
    "1. Perform error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1505f67-9124-410b-b7d0-a68767dbb6aa",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "... Check out the [xtreme](https://huggingface.co/datasets/xtreme) dataset on Huggingface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1913d1-7fb5-455f-a23a-9060d098fbec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME has 183 configurations\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names, load_dataset\n",
    "\n",
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d96c7ea-156e-4bb2-b2af-4d6691a65335",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
    "panx_subsets[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5557e81a-97ed-4b78-b332-aa7c4dd1c5b9",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "255b14c9-c05c-4b08-9f27-7e6274380cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xtreme (/home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295d00030d4a487fbd6384150addfb75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-e5ddf09f1ae095ec.arrow\n",
      "Loading cached shuffled indices for dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-25e7e2dd003d0fa6.arrow\n",
      "Loading cached shuffled indices for dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-73a95bc0accfea8b.arrow\n",
      "Found cached dataset xtreme (/home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101bb4379bb045a5b63ba09f91720022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-6ff29513007ec78b.arrow\n",
      "Loading cached shuffled indices for dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-c5c9a4fc19dfd7d6.arrow\n",
      "Loading cached shuffled indices for dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-9711ab25936b81b7.arrow\n",
      "Found cached dataset xtreme (/home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d45b36b70e1427084923d0d8f9fb3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-daa9a1770078307c.arrow\n",
      "Loading cached shuffled indices for dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-5e244c05031bab3c.arrow\n",
      "Loading cached shuffled indices for dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-497ee15c12bff58d.arrow\n",
      "Found cached dataset xtreme (/home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e487590c638f40d9b5ea9276aa95fd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-757845faa9fa6949.arrow\n",
      "Loading cached shuffled indices for dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-305cefc7ffa49fd9.arrow\n",
      "Loading cached shuffled indices for dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-e5ec5e6ba7c1237d.arrow\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# the major languages in Switzerland!\n",
    "langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
    "fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "\n",
    "for lang,frac in zip(langs, fracs):\n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (\n",
    "            ds[split]\n",
    "                .shuffle(seed=0)\n",
    "                .select(range(int(frac * ds[split].num_rows)))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ce6ad4-8050-4c0e-9486-97a17bc8b76e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of training examples</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                de    fr    it    en\n",
       "Number of training examples  12580  4580  1680  1180"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(\n",
    "    {lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs},\n",
    "    index=[\"Number of training examples\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998f91df-2feb-4b5b-8f2b-f38c7e51bbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'datasets.dataset_dict.DatasetDict'>, {'de': DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs'],\n",
      "        num_rows: 12580\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs'],\n",
      "        num_rows: 6290\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs'],\n",
      "        num_rows: 6290\n",
      "    })\n",
      "}), 'fr': DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs'],\n",
      "        num_rows: 4580\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs'],\n",
      "        num_rows: 2290\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs'],\n",
      "        num_rows: 2290\n",
      "    })\n",
      "}), 'it': DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs'],\n",
      "        num_rows: 1680\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs'],\n",
      "        num_rows: 840\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs'],\n",
      "        num_rows: 840\n",
      "    })\n",
      "}), 'en': DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs'],\n",
      "        num_rows: 1180\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs'],\n",
      "        num_rows: 590\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs'],\n",
      "        num_rows: 590\n",
      "    })\n",
      "})})\n"
     ]
    }
   ],
   "source": [
    "print(panx_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7849a7a1-a2ec-4063-8e58-e15e24679340",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n"
     ]
    }
   ],
   "source": [
    "element = panx_ch[\"de\"][\"train\"][0]\n",
    "print(type(element))\n",
    "for key, value in element.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96af1e9d-d32b-4b06-9a30-10f41e974a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "ner_tags: Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\n",
      "langs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_ch[\"de\"][\"train\"].features.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb3214ec-b4a4-4faa-b934-bd3b9b4c6cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n"
     ]
    }
   ],
   "source": [
    "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12167f83-1f33-4eca-bdd7-d095fe348088",
   "metadata": {
    "tags": []
   },
   "source": [
    "type(tags)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e185561-08bd-4a85-847d-4af22f361c93",
   "metadata": {
    "tags": []
   },
   "source": [
    "dir(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "331001ba-00c6-4bde-b1d7-00e6b28bc839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "999fac6e-ac5c-48a4-9f86-13d4a2dd1c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-f46d0659f7a52a15.arrow\n",
      "Loading cached processed dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-333a88ffd23068c4.arrow\n",
      "Loading cached processed dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-e6d4015812e9aa22.arrow\n"
     ]
    }
   ],
   "source": [
    "panx_de = panx_ch[\"de\"].map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4263a3e3-b684-4ca5-8165-503afeb13cfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
      "        num_rows: 12580\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
      "        num_rows: 6290\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n",
      "        num_rows: 6290\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(panx_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bc0b847-ad24-4c80-b5c1-91c4df3f72ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>2.000</td>\n",
       "      <td>Einwohnern</td>\n",
       "      <td>an</td>\n",
       "      <td>der</td>\n",
       "      <td>Danziger</td>\n",
       "      <td>Bucht</td>\n",
       "      <td>in</td>\n",
       "      <td>der</td>\n",
       "      <td>polnischen</td>\n",
       "      <td>Woiwodschaft</td>\n",
       "      <td>Pommern</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1   2    3         4      5   6    7           8   \\\n",
       "Tokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \n",
       "Tags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n",
       "\n",
       "                  9        10 11  \n",
       "Tokens  Woiwodschaft  Pommern  .  \n",
       "Tags           B-LOC    I-LOC  O  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_example = panx_de[\"train\"][0]\n",
    "pd.DataFrame(\n",
    "    [de_example[\"tokens\"], de_example[\"ner_tags_str\"]],\n",
    "    [\"Tokens\", \"Tags\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "467f1ea9-4612-4403-9402-e5f5ee9e8493",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>6186</td>\n",
       "      <td>5366</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>3172</td>\n",
       "      <td>2683</td>\n",
       "      <td>2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>3180</td>\n",
       "      <td>2573</td>\n",
       "      <td>3071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LOC   ORG   PER\n",
       "train       6186  5366  5810\n",
       "validation  3172  2683  2893\n",
       "test        3180  2573  3071"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in panx_de.items():\n",
    "    for row in dataset[\"ner_tags_str\"]:\n",
    "        for tag in row:\n",
    "            if tag.startswith(\"B\"):\n",
    "                tag_type = tag.split(\"-\")[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "pd.DataFrame.from_dict(\n",
    "    split2freqs,\n",
    "    orient=\"index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd9b64-e4e4-4d2f-96b2-8c4dbc3d7112",
   "metadata": {},
   "source": [
    "## Multilingual Transformers\n",
    "\n",
    "XLM-Roberta supports 100 languages, Japanese included!\n",
    "\n",
    "Suggested reading:\n",
    "\n",
    "* [A. Conneau, K. Khandelwal, et al.; 2020; \"Unsupervised Cross-lingual Representation Learning at Scale\"](https://arxiv.org/pdf/1911.02116.pdf)\n",
    "* [T. Kudo, J. Richardson; 2018; \"SentencePiece: A Simple and Language Independent Subword Tokenizer and Detokenizer for Neural Text Processing\"](https://arxiv.org/pdf/1808.06226.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ce814-a92c-4584-aa48-09381caeef6d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603f162a-47e7-490e-833e-2978e34bc9f3",
   "metadata": {},
   "source": [
    "## A Closer Look at Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02acb81b-3314-47ae-9b83-ed8c874343ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a44c5eef-ad65-4025-afde-15d6bc0ee89b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Jack Sparrow loves New York!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b092693-1cd6-4c3a-8b2d-cc004447f4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "xlmr_tokens = xlmr_tokenizer(text).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be602eee-dd41-4e09-8ed4-898d72e7afde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT tokens: ['[CLS]', 'Jack', 'Spa', '##rrow', 'loves', 'New', 'York', '!', '[SEP]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS]JackSpa##rrowlovesNewYork![SEP]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"BERT tokens: {bert_tokens}\")\n",
    "''.join(bert_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bd87342-c938-43f6-9163-eb04e82a6633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML-R tokens: ['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s> Jack Sparrow loves New York!</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"XML-R tokens: {xlmr_tokens}\")\n",
    "''.join(xlmr_tokens).replace(u'\\u2581', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849bade-d11e-4953-b955-7039388a721f",
   "metadata": {},
   "source": [
    "Suggested reading:\n",
    "\n",
    "* [J. Devlin, et al., \"BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding\"](https://arxiv.org/abs/1810.04805)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd0bc62-a803-4441-a9b2-253c25830b21",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86549ad-fe67-45bd-a2a4-2f91af153f23",
   "metadata": {},
   "source": [
    "## Creating a Custom Model for Token Classification\n",
    "\n",
    "Or, How to build a custom head for any task and just mount it on top of a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e99a1cc7-949b-4506-a413-ee44f5bec82f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec73ac5b-2ecc-48d7-a9b6-b2086ecee6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        \n",
    "        # load model body!\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        \n",
    "        # set up token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        \n",
    "        # load and initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        input_ids=None, \n",
    "        attention_mask=None, \n",
    "        token_type_ids=None,\n",
    "        labels=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # use model body to get encoder representations\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        # apply classifier to encoding representation\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        \n",
    "        # calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, self.num_labels),\n",
    "                labels.view(-1)\n",
    "            )\n",
    "        \n",
    "        # return\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693dc2f3-0e99-4386-89d4-61c52afb1e95",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f2a8b1-fddd-441b-8180-72c023d5518f",
   "metadata": {},
   "source": [
    "## Loading a Custom Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77e5d46c-fc67-4ac6-846b-9961815b162b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fc13e38-5a90-4ee4-acd2-4a53d3e03dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "xlmr_config = AutoConfig.from_pretrained(\n",
    "    xlmr_model_name,\n",
    "    num_labels=tags.num_classes,\n",
    "    id2label=index2tag,\n",
    "    label2id=tag2index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b22ce47f-ca7c-4588-9024-74bbc01f897b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-PER\",\n",
      "    \"2\": \"I-PER\",\n",
      "    \"3\": \"B-ORG\",\n",
      "    \"4\": \"I-ORG\",\n",
      "    \"5\": \"B-LOC\",\n",
      "    \"6\": \"I-LOC\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-LOC\": 5,\n",
      "    \"B-ORG\": 3,\n",
      "    \"B-PER\": 1,\n",
      "    \"I-LOC\": 6,\n",
      "    \"I-ORG\": 4,\n",
      "    \"I-PER\": 2,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(xlmr_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba9957b4-002b-4d53-b996-f4775da5f52c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'roberta.embeddings.position_ids', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "xlmr_model = (XLMRobertaForTokenClassification\n",
    "              .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "              .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d1315ee-8eda-4ba1-8be7-4e1badd98f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inputs IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>21763</td>\n",
       "      <td>37456</td>\n",
       "      <td>15555</td>\n",
       "      <td>5161</td>\n",
       "      <td>7</td>\n",
       "      <td>2356</td>\n",
       "      <td>5753</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0      1      2      3      4  5     6      7   8     9\n",
       "Tokens      <s>  ▁Jack  ▁Spar    row  ▁love  s  ▁New  ▁York   !  </s>\n",
       "Inputs IDs    0  21763  37456  15555   5161  7  2356   5753  38     2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "pd.DataFrame(\n",
    "    [xlmr_tokens, input_ids[0].numpy()],\n",
    "    index = [\"Tokens\", \"Inputs IDs\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a29ddf1d-e731-48ac-864e-ae9e31d969d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 10\n",
      "Shape of outputs: torch.Size([1, 10, 7])\n"
     ]
    }
   ],
   "source": [
    "outputs = xlmr_model(input_ids.to(device)).logits\n",
    "\n",
    "predictions = torch.argmax(outputs, dim=2)\n",
    "\n",
    "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
    "print(f\"Shape of outputs: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7dfbc19-261a-4299-83c4-a83ee0fb67b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7      8      9\n",
       "Tokens    <s>  ▁Jack  ▁Spar    row  ▁love      s   ▁New  ▁York      !   </s>\n",
       "Tags    B-LOC  B-LOC  B-LOC  B-LOC  B-LOC  I-PER  B-LOC  B-LOC  I-PER  B-LOC"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "pd.DataFrame(\n",
    "    [xlmr_tokens, preds],\n",
    "    index = [\"Tokens\", \"Tags\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b6fc51e-b5bc-4e69-b639-295ba9a5cdff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    # get tokens with special characters\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    \n",
    "    # encode the sequence into IDs\n",
    "    input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    \n",
    "    # get prediction as distribution over 7 possible classes\n",
    "    outputs = model(input_ids)[0]\n",
    "    \n",
    "    # take argmax to get most likely class per token\n",
    "    predictions = torch.argmax(outputs, dim=2)\n",
    "    \n",
    "    # convert to DataFrame\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "    \n",
    "    return pd.DataFrame([tokens, preds], index = [\"Tokens\", \"Tags\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d8672-870e-4ed1-b816-a414c06cdeb5",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f2133a-3b7f-4ac7-aa5d-85ae3a77b617",
   "metadata": {},
   "source": [
    "## Tokenizing Texts for NER\n",
    "\n",
    "   `function(examples: Dict[str, List]) -> Dict[str, List]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d721392b-df3e-4826-b6ee-2f9c485a5305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b22a69-81ae-412c-b39f-0b3164819bb3",
   "metadata": {},
   "source": [
    "_what is `is_split_into_words`?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8b70b8d-cead-4a5c-b010-7ef4925edbed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1           2  3    4     5     6   7    8      9   ...   15  \\\n",
       "Tokens  <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  ▁Wo   \n",
       "\n",
       "       16   17      18   19    20 21 22 23    24  \n",
       "Tokens  i  wod  schaft  ▁Po  mmer  n  ▁  .  </s>  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = xlmr_tokenizer(\n",
    "    de_example[\"tokens\"], \n",
    "    is_split_into_words=True\n",
    ")\n",
    "\n",
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "\n",
    "pd.DataFrame([tokens], index=[\"Tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1518d285-b2a5-48f7-adbc-0894f56f7290",
   "metadata": {},
   "source": [
    "_what is `word_ids`?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecd756c8-206d-4a69-bc7d-306d2cec995d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1           2  3    4     5     6   7    8      9   ...  \\\n",
       "Tokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \n",
       "Word IDs  None       0           1  1    2     3     4   4    4      5  ...   \n",
       "\n",
       "           15 16   17      18   19    20  21  22  23    24  \n",
       "Tokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \n",
       "Word IDs    9  9    9       9   10    10  10  11  11  None  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "\n",
    "pd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad9167b5-7b5e-47f5-a81a-e828e5fc2a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label IDs</th>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1           2     3    4     5      6     7     8   \\\n",
       "Tokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \n",
       "Word IDs   None       0           1     1    2     3      4     4     4   \n",
       "Label IDs  -100       0           0  -100    0     0      5  -100  -100   \n",
       "Labels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n",
       "\n",
       "              9   ...     15    16    17      18     19    20    21  22    23  \\\n",
       "Tokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \n",
       "Word IDs       5  ...      9     9     9       9     10    10    10  11    11   \n",
       "Label IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \n",
       "Labels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n",
       "\n",
       "             24  \n",
       "Tokens     </s>  \n",
       "Word IDs   None  \n",
       "Label IDs  -100  \n",
       "Labels      IGN  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_word_index = None\n",
    "label_ids = []\n",
    "\n",
    "for word_idx in word_ids:\n",
    "    if word_idx is None or word_idx == previous_word_index:\n",
    "        label_ids.append(-100)\n",
    "    elif word_idx != previous_word_index:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    previous_word_index = word_idx\n",
    "\n",
    "labels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n",
    "index  = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "\n",
    "pd.DataFrame(\n",
    "    [tokens, word_ids, label_ids, labels],\n",
    "    index = index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf1a201a-bd7b-4264-bfc4-141e5af7b519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation = True,\n",
    "        is_split_into_words = True\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "030a4f8d-1a01-42ac-8ec5-91ad5159eac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(\n",
    "        tokenize_and_align_labels, \n",
    "        batched = True,\n",
    "        remove_columns = [ \"langs\", \"ner_tags\", \"tokens\" ]\n",
    "    )\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed4a857b-d195-4f65-9ca2-5872a244cfbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-9a0dfe82ca83754c.arrow\n",
      "Loading cached processed dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-e21cd32e940e46a6.arrow\n",
      "Loading cached processed dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-eaf860e23239e210.arrow\n"
     ]
    }
   ],
   "source": [
    "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "642f8047-d8da-4c3b-8994-d54f7383c6f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 12580\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 6290\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 6290\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(panx_de_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddda2e6f-2fe2-4d03-8fe4-5c3ec05d6478",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7987e2-7e1e-4a65-93a7-5a8a8b1d0a9c",
   "metadata": {},
   "source": [
    "## Performance Measures\n",
    "\n",
    "`seqeval` ... is...?\n",
    "\n",
    "Also see the [Metrics Card for `seqeval` on huggingface](https://huggingface.co/spaces/evaluate-metric/seqeval).\n",
    "\n",
    "#### Regarding the `seqeval` output...\n",
    "\n",
    "##### precision\n",
    "\n",
    "... is...?\n",
    "\n",
    "##### recall\n",
    "\n",
    "... is...?\n",
    "\n",
    "##### F1-score\n",
    "\n",
    "... is...?\n",
    "\n",
    "##### support\n",
    "\n",
    "... is...?\n",
    "\n",
    "##### micro average vs macro average vs weighted average\n",
    "\n",
    "... see [this answer to the question \"Micro Average vs Macro average Performance in a Multiclass classification setting\" on the Data Science Stack Exchange](https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin/24051#24051)...\n",
    "\n",
    "... and [another on macro average vs weighted average in `sklearn.metrics.classification_report`](https://datascience.stackexchange.com/questions/65839/macro-average-and-weighted-average-meaning-in-classification-report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23c2e1bf-c21f-4a04-9bdb-f7aaa6021ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "\n",
    "y_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86ee619-7737-4fe2-9371-918545a07e21",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05d820-e865-4fc3-8629-e59b3e171963",
   "metadata": {},
   "source": [
    "## Fine-tuning XLM-RoBERTa\n",
    "\n",
    "### Create `TrainingArguments`\n",
    "\n",
    "* Before instantiating your `Trainer`, create a `TrainingArguments` to access all the points of customization during training. In this example, our arguments encompass things like:\n",
    "   * `output_dir` ... output directory where the model predictions and checkpoints will be written.\n",
    "   * `log_level`\n",
    "   * `num_train_epochs`\n",
    "   * `per_device_train_batch_size`\n",
    "   * `save_steps`\n",
    "   * `logging_steps`\n",
    "   <br/>... among other things... <p/>\n",
    "* During training, if you do not take certain steps, you may see a warning message when invoking `trainer.train()`:\n",
    "\n",
    "<pre>\n",
    "/opt/conda/envs/transformers-py38/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
    "</pre>\n",
    "\n",
    "To avoid this, try explicitly using the `adamw_torch` optimizer in your training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9b5ce2f-6cf6-4ad6-ae4c-5448cc528331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 24\n",
    "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    log_level=\"error\",\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_steps=1e6,\n",
    "    weight_decay=0.01,\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=True,\n",
    "    optim=\"adamw_torch\",    # let's get rid of that annoying warning message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6077d81d-1fa5-4c1c-8bd9-a18cc590901d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9039b961fe0e4b139ab180bae1268ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# no error, means this call succeeded!\n",
    "#\n",
    "# you can click on the log entries icon in the lower\n",
    "# left-hand portion of the window pane to see the\n",
    "# logging messages indicating whether login\n",
    "# succeeded or not\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3d168-cba8-4fb9-ab7f-4369c94c2a3c",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef9eec-9c29-41d0-b5d8-5958cb9397c0",
   "metadata": {},
   "source": [
    "### Create `transformers.Trainer`\n",
    "\n",
    "In this example, we specify the following arguments when instantiating [`transformers.Trainer`](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer):\n",
    "\n",
    "##### `model_init` \n",
    "*  A function that instantiates the model to be used. If provided, each call to `train()` will start from a new instance of the model as given by this function.\n",
    "\n",
    "##### `args` \n",
    "* define a `TrainingArguments` object instance that will contain all the hyperparameters the `Trainer` will use for training and evaluation.\n",
    "\n",
    "##### `data_collator`\n",
    "* The function to use to form a batch from a list of elements of train_dataset or eval_dataset. Will default to `default_data_collator(){ if no tokenizer is provided, an instance of DataCollatorWithPadding otherwise.\n",
    "\n",
    "##### `compute_metrics`\n",
    "* The function that will be used to compute metrics at evaluation. Must take a `EvalPrediction` and return a dictionary string to metric values.\n",
    "\n",
    "##### `train_dataset`\n",
    "* The dataset to use for training. If it is a `Dataset`, columns not accepted by the `model.forward()` method are automatically removed.\n",
    "\n",
    "##### `eval_dataset`\n",
    "* The dataset to use for evaluation. If it is a `Dataset`, columns not accepted by the `model.forward()` method are automatically removed. If it is a dictionary, it will evaluate on each dataset prepending the dictionary key to the metric name.\n",
    "\n",
    "##### `tokenizer`\n",
    "* The tokenizer used to preprocess the data. If provided, will be used to automatically pad the inputs to the maximum length when batching inputs, and it will be saved along the model to make it easier to rerun an interrupted training or reuse the fine-tuned model.\n",
    "\n",
    "\n",
    "OK, let's get into the more important details of `Trainer`..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b5a41-cba6-4730-85af-33c94ba924e3",
   "metadata": {},
   "source": [
    "### `model_init`\n",
    "\n",
    "An argument when creating an instance of the `Trainer` object itself, this helper function will let us instantiate new model instance with each call to `Trainer.train()`.\n",
    "\n",
    "Here, note that we using the `from_pretrained` function in our custom `XLMRobertaForTokenClassification` class, passing in:\n",
    "* `xlmr_model_name`\n",
    "* `xlmr_config`\n",
    "\n",
    "Note that we also put this newly-created model instance on the `device` (GPU), and then return a handle to that instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46c9ca0b-2c57-4985-bce1-ec3ce8b194e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return (\n",
    "        XLMRobertaForTokenClassification\n",
    "            .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "            .to(device)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16693d67-08d6-4802-a41e-6430ffdeb808",
   "metadata": {},
   "source": [
    "### `compute_metrics`\n",
    "\n",
    "A function called during training to calculate statistics.\n",
    "\n",
    "This function must take an instance of [`EvalPrediction`](https://huggingface.co/docs/transformers/v4.26.1/en/internal/trainer_utils) as its sole argument, and then return a dictionary of string to metric values. This `EvalPrediction` argument has the following properties for use when calculating training statistics:\n",
    "* `predictions` (`np.ndarray`) — Predictions of the model.\n",
    "* `label_ids` (`np.ndarray`) — Targets to be matched.\n",
    "* `inputs` (`np.ndarray`, optional) — "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "002c06ad-3971-42f5-8d9a-82a48245c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], []\n",
    "    \n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # ignore label IDS == -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "    \n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bda7e1e9-22f0-4103-b855-c5a162f95924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_predictions(\n",
    "        eval_pred.predictions, \n",
    "        eval_pred.label_ids\n",
    "    )\n",
    "    return {\"f1\": f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e48372e-1bd5-445e-b682-55346d5ff1ed",
   "metadata": {},
   "source": [
    "### `data_collator`\n",
    "\n",
    "* Data collators are objects that will form a batch by using a list of dataset elements as input. These elements are of the same type as the elements of `train_dataset` or `eval_dataset`.\n",
    "\n",
    "* Here, we use an instance of [`transformers.DataCollatorForTokenClassification`](https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/data_collator#transformers.DataCollatorForTokenClassification), passing in our `xlmr_tokenizer` tokenizer, which as `XLMRobertaTokenizerFast` is an subclass of [`transformers.PreTrainedTokenizerFast`](https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast). This is a case of one of the advantages of leveraging huggingface's abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f86865d7-88a3-4aca-bb48-266d00f1af2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd10f66-8e36-43b9-a07a-d70fb8c31385",
   "metadata": {},
   "source": [
    "### blah\n",
    "\n",
    "Instantiate `Trainer`, passing in all of our custom objects and data needed for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ce69d90-4bf2-4124-ab75-a6b0095b215b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/the_oriental_love_ring/dev/github/transformers-gcp/xlm-roberta-base-finetuned-panx-de is already a clone of https://huggingface.co/buruzaemon/xlm-roberta-base-finetuned-panx-de. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=panx_de_encoded[\"train\"],\n",
    "    eval_dataset=panx_de_encoded[\"validation\"],\n",
    "    tokenizer=xlmr_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7d679e7-1bf5-4b4f-afd1-11ca1067aa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1575' max='1575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1575/1575 08:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.258800</td>\n",
       "      <td>0.164123</td>\n",
       "      <td>0.814524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.139933</td>\n",
       "      <td>0.849726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.138362</td>\n",
       "      <td>0.863279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1575, training_loss=0.15599132471614413, metrics={'train_runtime': 530.3003, 'train_samples_per_second': 71.167, 'train_steps_per_second': 2.97, 'total_flos': 863012377186080.0, 'train_loss': 0.15599132471614413, 'epoch': 3.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a464a91d-6510-4dff-abbb-5298d10ab09c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/buruzaemon/xlm-roberta-base-finetuned-panx-de\n",
      "   994258e..99b0744  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/buruzaemon/xlm-roberta-base-finetuned-panx-de/commit/99b0744da390a38aab6990ab7fce317e5cd64224'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8997fd2-ed6a-4230-bcb8-4552725a22dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁ist</td>\n",
       "      <td>▁ein</td>\n",
       "      <td>▁Informati</td>\n",
       "      <td>ker</td>\n",
       "      <td>▁bei</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁Kaliforni</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3     4     5           6    7     8        9   \\\n",
       "Tokens  <s>  ▁Jeff    ▁De     an  ▁ist  ▁ein  ▁Informati  ker  ▁bei  ▁Google   \n",
       "Tags      O  B-PER  I-PER  I-PER     O     O           O    O     O    B-ORG   \n",
       "\n",
       "         10          11     12    13  \n",
       "Tokens  ▁in  ▁Kaliforni     en  </s>  \n",
       "Tags      O       B-LOC  I-LOC     O  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_de = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\n",
    "\n",
    "tag_text(text_de, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120bd458-8683-42f7-899d-c5d14ffe15d4",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d48425-9f99-4823-af8b-a8f2ac22ba3f",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bddfb777-137b-485e-81ca-b07e0765e814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    # convert dict of lists to list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    \n",
    "    # pad inputs and labels and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # pass data through model\n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        \n",
    "        # logit.size: [batch_size, sequence_length, classes]\n",
    "        # predict class with larget logit vlaue on classes axis\n",
    "        # don't forget to \"bring\" that value back to the CPU,\n",
    "        # and convert to Numpy ???\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "\n",
    "    # calculate loss per token after flattening the batch dimension with view\n",
    "    loss = cross_entropy(\n",
    "        output.logits.view(-1, 7), # 7 NER types (classes)\n",
    "        labels.view(-1),\n",
    "        reduction=\"none\"\n",
    "    )\n",
    "    \n",
    "    # unflatten batch dimension, move computation back to CPU, and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "    \n",
    "    return {\"loss\": loss, \"predicted_label\": predicted_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ab2af6f-56c2-4dc7-9b84-5b69d329a46e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function forward_pass_with_label at 0x7f756d990a60> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Loading cached processed dataset at /home/the_oriental_love_ring/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/29f5d57a48779f37ccb75cb8708d1095448aad0713b425bdc1ff9a4a128a56e4/cache-1c80317fa3b1799d.arrow\n"
     ]
    }
   ],
   "source": [
    "valid_set = panx_de_encoded[\"validation\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
    "df = valid_set.to_pandas()\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e14101e1-6b72-4c78-b216-e37005d66338",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]</td>\n",
       "      <td>[0.0, 0.011267012, 0.0, 0.03502869, 0.02726594...</td>\n",
       "      <td>[I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]</td>\n",
       "      <td>[&lt;s&gt;, ▁Ham, a, ▁(, ▁Unternehmen, ▁), &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            input_ids         attention_mask  \\\n",
       "0  [0, 10699, 11, 15, 16104, 1388, 2]  [1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                        labels  \\\n",
       "0  [IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]   \n",
       "\n",
       "                                                loss  \\\n",
       "0  [0.0, 0.011267012, 0.0, 0.03502869, 0.02726594...   \n",
       "\n",
       "                                     predicted_label  \\\n",
       "0  [I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]   \n",
       "\n",
       "                                 input_tokens  \n",
       "0  [<s>, ▁Ham, a, ▁(, ▁Unternehmen, ▁), </s>]  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "\n",
    "# add a new column for the input tokens\n",
    "df[\"input_tokens\"] = df[\"input_ids\"].apply(\n",
    "    lambda x: xlmr_tokenizer.convert_ids_to_tokens(x)\n",
    ")\n",
    "\n",
    "# transform the column for predicted labels\n",
    "# from label_id to actual label\n",
    "df[\"predicted_label\"] = df[\"predicted_label\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x]\n",
    ")\n",
    " \n",
    "# transform the column for actual labels\n",
    "# from label_id to actual label\n",
    "df[\"labels\"] = df[\"labels\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x]\n",
    ")\n",
    "\n",
    "# add a new column for showing loss\n",
    "# per input_id in example x\n",
    "df[\"loss\"] = df.apply(\n",
    "    lambda x: x['loss'][:len(x['input_ids'])], axis=1\n",
    ")\n",
    "\n",
    "# transform the predicted_label column \n",
    "# to show the predicted label type \n",
    "# for each token in example x\n",
    "df[\"predicted_label\"] = df.apply(\n",
    "    lambda x: x[\"predicted_label\"][:len(x['input_ids'])], axis=1\n",
    ")\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88152178-1b3a-47fe-9132-bfd463999cea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10699</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.01</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>▁Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.04</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16104</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.03</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁Unternehmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1388</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.03</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56530</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "      <td>▁WE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83982</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.76</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>▁Luz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.45</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>▁a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids attention_mask labels  loss predicted_label  input_tokens\n",
       "0     10699              1  B-ORG  0.01           B-ORG          ▁Ham\n",
       "0        15              1  I-ORG  0.04           I-ORG            ▁(\n",
       "0     16104              1  I-ORG  0.03           I-ORG  ▁Unternehmen\n",
       "0      1388              1  I-ORG  0.03           I-ORG            ▁)\n",
       "1     56530              1      O  0.00               O           ▁WE\n",
       "1     83982              1  B-ORG  0.76           B-ORG          ▁Luz\n",
       "1        10              1  I-ORG  0.45           I-ORG            ▁a"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = df.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f570ba38-eae5-4ed2-aca7-f6b2ac10d3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>▁</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁von</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁/</td>\n",
       "      <td>▁und</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6066</td>\n",
       "      <td>989</td>\n",
       "      <td>808</td>\n",
       "      <td>1388</td>\n",
       "      <td>163</td>\n",
       "      <td>1171</td>\n",
       "      <td>246</td>\n",
       "      <td>2898</td>\n",
       "      <td>246</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>217.18</td>\n",
       "      <td>129.63</td>\n",
       "      <td>126.04</td>\n",
       "      <td>122.36</td>\n",
       "      <td>94.92</td>\n",
       "      <td>86.88</td>\n",
       "      <td>69.93</td>\n",
       "      <td>68.33</td>\n",
       "      <td>67.03</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0       1       2       3      4      5      6      7  \\\n",
       "input_tokens       ▁     ▁in    ▁von    ▁der     ▁/   ▁und     ▁(    ▁''   \n",
       "count           6066     989     808    1388    163   1171    246   2898   \n",
       "mean            0.04    0.13    0.16    0.09   0.58   0.07   0.28   0.02   \n",
       "sum           217.18  129.63  126.04  122.36  94.92  86.88  69.93  68.33   \n",
       "\n",
       "                  8     9  \n",
       "input_tokens     ▁)    ▁A  \n",
       "count           246   125  \n",
       "mean           0.27  0.44  \n",
       "sum           67.03  55.6  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "        .agg([\"count\", \"mean\", \"sum\"])\n",
    "        .droplevel(level=0, axis=1)    # get rid of multi-level columns\n",
    "        .sort_values(by=\"sum\", ascending=False)\n",
    "        .reset_index()\n",
    "        .round(2)\n",
    "        .head(10)\n",
    "        .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c1ba700-16f9-4974-83c8-b688ab94c36c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2683</td>\n",
       "      <td>1462</td>\n",
       "      <td>3820</td>\n",
       "      <td>3172</td>\n",
       "      <td>2893</td>\n",
       "      <td>4139</td>\n",
       "      <td>43648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>1712.62</td>\n",
       "      <td>874.23</td>\n",
       "      <td>1839.89</td>\n",
       "      <td>1058.45</td>\n",
       "      <td>797.83</td>\n",
       "      <td>728.21</td>\n",
       "      <td>1343.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0       1        2        3       4       5        6\n",
       "labels    B-ORG   I-LOC    I-ORG    B-LOC   B-PER   I-PER        O\n",
       "count      2683    1462     3820     3172    2893    4139    43648\n",
       "mean       0.64     0.6     0.48     0.33    0.28    0.18     0.03\n",
       "sum     1712.62  874.23  1839.89  1058.45  797.83  728.21  1343.23"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"labels\")[[\"loss\"]]\n",
    "        .agg([\"count\", \"mean\", \"sum\"])\n",
    "        .droplevel(level=0, axis=1)\n",
    "        .sort_values(by=\"mean\", ascending=False)\n",
    "        .reset_index()\n",
    "        .round(2)\n",
    "        .T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c384818-b702-472e-a1e9-07ae3e50c62f",
   "metadata": {},
   "source": [
    "NOTE\n",
    "\n",
    "2 errors in the code snippet listed on page 112:\n",
    "* missing the `import matplotlib.pyplot as plt` bit\n",
    "* order of `y_preds` and `y_true` reversed for `plot_confusion_matrix`?!\n",
    "\n",
    "Corrected, it should be as follows below.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a08d9323-5507-4046-b646-3704730d6b64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_preds, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    df_tokens[\"labels\"],\n",
    "    df_tokens[\"predicted_label\"],\n",
    "    tags.names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a0d36c-3f9e-42cd-97eb-2b81f5094147",
   "metadata": {},
   "source": [
    "If this understanding is correct, we can reach these conclusions:\n",
    "\n",
    "1. `B-PER` is most often mistaken for `O` at 0.07\n",
    "1. `B-PER` is also often mistaken for `I-LOC` at 0.07\n",
    "1. `B-ORG` is most often mistaken for `I-ORG` at 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e111d5-a0d0-49b3-ab6a-0032fe1b917f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
